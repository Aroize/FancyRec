{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession, Row\n",
    "from utils import ndcg, hr, flood_negative_samples\n",
    "import json\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import *\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from ncf.dataset import ItemDataset, ValidationDataset\n",
    "from ncf.model import GMF, MLP, NeuMF, UserNeuMF, train_ncf, train_user_neu, load_pretrained_weights_neu_mf_from_path, evaluate_neu, evaluate_user_neu\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchsummaryX import summary\n",
    "from hparams import Hparam\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import os\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = 'local[*]'\n",
    "app_name = 'vk_2020_als'\n",
    "sc = SparkContext(master, app_name)\n",
    "spark = SparkSession.builder.master(master).appName(app_name).getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обработка пользователей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+------+---------+-------+\n",
      "|age|country|gender|playcount|user_id|\n",
      "+---+-------+------+---------+-------+\n",
      "| 24|     US|     f|   221012|      1|\n",
      "+---+-------+------+---------+-------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def parse_user(user):\n",
    "    user_id = int(user[0])\n",
    "    try:\n",
    "        info_json = json.loads(user[1])\n",
    "        age = info_json['age']\n",
    "        country = info_json['country']\n",
    "        gender = info_json['gender']\n",
    "        playcount = info_json['playcount']\n",
    "    except:\n",
    "        age = 0\n",
    "        country = 'Nan'\n",
    "        gender = 'Nan'\n",
    "        playcount = 0\n",
    "    return (user_id, age, country, gender, playcount)\n",
    "        \n",
    "\n",
    "\n",
    "user_dataframe = spark.read.csv('../data/entities/users.idomaar', header=False, sep='\\t')\n",
    "user_dataframe = user_dataframe.drop('_c0', '_c2')\n",
    "user_rdd = user_dataframe.rdd.map(parse_user)\n",
    "user_dataframe = user_rdd.map(lambda row: Row(user_id=row[0], age=row[1], country=row[2], gender=row[3], playcount=row[4])).toDF()\n",
    "user_dataframe.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обработка треков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+---+--------------------+--------------------+\n",
      "|  _c0|_c1|_c2|                 _c3|                 _c4|\n",
      "+-----+---+---+--------------------+--------------------+\n",
      "|track|  0| -1|{\"duration\":-1,\"p...|{\"artists\":[{\"typ...|\n",
      "+-----+---+---+--------------------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tracks_dataframe = spark.read.csv('../data/entities/tracks.idomaar', sep='\\t', header=False)\n",
    "tracks_dataframe.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+----+--------+\n",
      "|artist_id|duration|tags|track_id|\n",
      "+---------+--------+----+--------+\n",
      "|        0|      -1|  []|       0|\n",
      "+---------+--------+----+--------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def parse_track(track):\n",
    "    track_id = int(track[0])\n",
    "    info_json = json.loads(track[1])\n",
    "    \n",
    "    duration = info_json['duration']\n",
    "    duration = int(duration) if duration is not None else -1\n",
    "    \n",
    "    links_json = json.loads(track[2])\n",
    "    artists = links_json['artists']\n",
    "    # Проверкой было установлено, что для каждой записи указан только один артист (те len(artists) == 1)\n",
    "    assert len(artists) == 1\n",
    "    artist_id = artists[0]['id']\n",
    "    \n",
    "    tags = links_json['tags']\n",
    "    # В некоторых треках вместо пустого листа стоит null\n",
    "    if tags is None:\n",
    "        tags = []\n",
    "    else:\n",
    "        tags = filter(lambda obj: obj['type'] == 'tag', tags)\n",
    "        tags = list(map(lambda obj: obj['id'], tags))\n",
    "    return (track_id, artist_id, duration, tags)\n",
    "\n",
    "tracks_dataframe = tracks_dataframe.drop('_c0', '_c2')\n",
    "tracks_rdd = tracks_dataframe.rdd.map(parse_track)\n",
    "tracks_dataframe = tracks_rdd.map(lambda row: Row(track_id=row[0], artist_id=row[1], duration=row[2], tags=row[3])).toDF()\n",
    "tracks_dataframe.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обработка сессий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------+----------+--------------------+\n",
      "|          _c0|   _c1|       _c2|                 _c3|\n",
      "+-------------+------+----------+--------------------+\n",
      "|event.session|287144|1390231051|{\"numtracks\":23,\"...|\n",
      "+-------------+------+----------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "session_dataframe = spark.read.csv('../data/relations/sessions.idomaar', sep='\\t', header=False)\n",
    "session_dataframe.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+-------+\n",
      "| timestamp|              tracks|user_id|\n",
      "+----------+--------------------+-------+\n",
      "|1390231051|[[4698874, 58], [...|  44361|\n",
      "+----------+--------------------+-------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Формат файла сессий немного поломаный, там не разделены строки колонок info и links\n",
    "def parse_session(session):\n",
    "    session_timestamp = int(session[0])\n",
    "    splitted = session[1].split()\n",
    "    assert len(splitted) == 2\n",
    "    linked_json = splitted[1]\n",
    "    linked_json = json.loads(linked_json)\n",
    "    \n",
    "    subjects = linked_json['subjects'][0]\n",
    "    objects = linked_json['objects']\n",
    "    \n",
    "    user_id = subjects['id']\n",
    "    \n",
    "    objects = list(filter(lambda track: track['action'] == 'play', objects))\n",
    "    tracks = [(obj['id'], obj['playtime']) for obj in objects]\n",
    "    \n",
    "    return (user_id, session_timestamp, tracks)\n",
    "\n",
    "session_dataframe = session_dataframe.drop('_c0', '_c1')\n",
    "session_rdd = session_dataframe.rdd.map(parse_session)\n",
    "session_dataframe = session_rdd.map(lambda row: Row(user_id=row[0], timestamp=row[1], tracks=row[2])).toDF()\n",
    "session_dataframe.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обработка артистов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+---+--------------------+---+\n",
      "|   _c0|   _c1|_c2|                 _c3|_c4|\n",
      "+------+------+---+--------------------+---+\n",
      "|person|145148| -1|{\"MBID\":null, \"na...| {}|\n",
      "+------+------+---+--------------------+---+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "artist_dataframe = spark.read.csv('../data/entities/persons.idomaar', header=None, sep='\\t')\n",
    "artist_dataframe.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+\n",
      "|artist_id|           nicknames|\n",
      "+---------+--------------------+\n",
      "|    18689|[[[Allison+Veltz,...|\n",
      "+---------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def parse_artist(artist):\n",
    "    artist_id = int(artist[0])\n",
    "    artist_info_json = json.loads(artist[1])\n",
    "    artist_name = artist_info_json['name']\n",
    "    artist_mbid = artist_info_json['MBID']\n",
    "    return (artist_id, (artist_name, artist_mbid))\n",
    "\n",
    "artist_dataframe = artist_dataframe.drop('_c0', '_c2', '_c4')\n",
    "artist_rdd = artist_dataframe.rdd.map(parse_artist).groupByKey()\n",
    "artist_dataframe = artist_rdd.map(lambda row: Row(artist_id=row[0], nicknames=row[1])).toDF()\n",
    "artist_dataframe.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обработка лайков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+--------------------+\n",
      "|       _c0|_c1|                 _c2|\n",
      "+----------+---+--------------------+\n",
      "|preference|  1|-1 {\"value\":\"love...|\n",
      "+----------+---+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "likes_dataframe = spark.read.csv('../data/relations/love.idomaar', sep='\\t', header=None)\n",
    "likes_dataframe.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+-------+\n",
      "|timestamp|track_id|user_id|\n",
      "+---------+--------+-------+\n",
      "|       -1| 2785601|  44542|\n",
      "+---------+--------+-------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def parse_like(like):\n",
    "    like = like[0]\n",
    "    rows = like.split()\n",
    "    timestamp = int(rows[0])\n",
    "    json_info = json.loads(rows[2] + rows[3])\n",
    "    subjects = json_info['subjects']\n",
    "    assert len(subjects) == 1\n",
    "    objects = json_info['objects']\n",
    "    assert len(objects) == 1\n",
    "    \n",
    "    uid = subjects[0]['id']\n",
    "    track_id = objects[0]['id']\n",
    "    return (uid, track_id, timestamp)\n",
    "\n",
    "\n",
    "likes_dataframe = likes_dataframe.drop('_c0', '_c1')\n",
    "likes_rdd = likes_dataframe.rdd.map(parse_like)\n",
    "likes_dataframe = likes_rdd.map(lambda row: Row(user_id=row[0], track_id=row[1], timestamp=row[2])).toDF()\n",
    "likes_dataframe.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сохраним полученные файлы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_rdd(rdd, path):\n",
    "    rdd_list = rdd.collect()\n",
    "    pickle.dump(rdd_list, open(path, 'wb'))\n",
    "    return rdd_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_list = dump_rdd(tracks_rdd, '../preprocessed_data/track_list.pckl')\n",
    "session_list = dump_rdd(session_rdd, '../preprocessed_data/session_list.pckl')\n",
    "artist_list = dump_rdd(artist_rdd, '../preprocessed_data/artist_list.pckl')\n",
    "likes_list = dump_rdd(likes_rdd, '../preprocessed_data/likes_list.pckl')\n",
    "user_list = dump_rdd(user_rdd, '../preprocessed_data/user_list.pckl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Препроцессинг для датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33828"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_full_info(user):\n",
    "    age = user[1]\n",
    "    country = user[2]\n",
    "    gender = user[3]\n",
    "    return age != 0 and country != 'Nan' and gender != 'Nan'\n",
    "full_info_users = list(filter(is_full_info, user_list))\n",
    "len(full_info_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.006414804304125"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_ages = list(map(lambda x: x[1], full_info_users))\n",
    "mean_age = np.mean(user_ages)\n",
    "mean_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_mean_age(user):\n",
    "    idx = user[0]\n",
    "    country = user[2]\n",
    "    gender = user[3]\n",
    "    age = user[1]\n",
    "    if age == 0:\n",
    "        age = 30\n",
    "    return (idx, age, country, gender)\n",
    "\n",
    "user_list = list(map(set_mean_age, user_list))\n",
    "pickle.dump(user_list, open('../preprocessed_data/user_list.pckl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 2764474/2764474 [00:31<00:00, 88372.46it/s]\n"
     ]
    }
   ],
   "source": [
    "session_list = pickle.load(open('../preprocessed_data/session_list.pckl', 'rb'))\n",
    "track_list = pickle.load(open('../preprocessed_data/track_list.pckl', 'rb'))\n",
    "# Поставим в соответсвие треку - ариста, теги нам не нужны\n",
    "track_to_artist = dict(map(lambda x: (x[0], [x[1], x[2]]), track_list))\n",
    "# Эмпирические значения порогов\n",
    "track_ratio_threshold = 0.3\n",
    "track_sec_threshold = 20\n",
    "artist_sessions = []\n",
    "for session in tqdm(session_list):\n",
    "    user_id, timestamp, tracks = session\n",
    "    artist_list = []\n",
    "    for track in tracks:\n",
    "        track_id, playtime = track\n",
    "        artist_id, duration = track_to_artist[track_id]\n",
    "        assert playtime > 0\n",
    "        if duration > 0:\n",
    "            # playtime в сек, а duration в мс\n",
    "            track_ratio = float(playtime * 10**3) / duration\n",
    "        else:\n",
    "            track_ratio = track_ratio_threshold if playtime >= track_sec_threshold else 0.0\n",
    "        if track_ratio >= track_ratio_threshold:\n",
    "            artist_list.append(artist_id)\n",
    "    artist_sessions.append((user_id, timestamp, artist_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2764474"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Посмотрим гистограмму частоты встречаемости артистов\n",
    "\n",
    "def get_freq_list(data):\n",
    "    counter = Counter()\n",
    "    for session in data:\n",
    "        for item in session:\n",
    "            counter[item] += 1\n",
    "    return [math.log(v) for _, v in counter.items()], counter\n",
    "\n",
    "artist_sessions = np.asarray(artist_sessions)\n",
    "artist_freq_list, artist_counter = get_freq_list(artist_sessions[:, 2])\n",
    "_ = plt.hist(artist_freq_list, bins=15)\n",
    "len(artist_sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1710615, 15496)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "counter = Counter()\n",
    "# Частота встречаемости пользователей в сессиях\n",
    "for uid, _, _ in artist_sessions:\n",
    "    counter[uid] += 1\n",
    "freq = [v for _,v in counter.items()]\n",
    "_ = plt.hist(list(map(lambda x: math.log(x),freq)), bins=25)\n",
    "\n",
    "artist_sessions = list(filter(lambda x: math.log(counter[x[0]]) > 4 and math.log(counter[x[0]]) < 6, artist_sessions))\n",
    "user_set = set()\n",
    "for uid, _, _ in artist_sessions:\n",
    "    user_set.add(uid)\n",
    "# всего сессий и всего уникальных пользователей\n",
    "len(artist_sessions), len(user_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89729"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Отфильтруем артистов, которые встречаются в сессиях слишком редко\n",
    "filtered_sessions = []\n",
    "for session in artist_sessions:\n",
    "    uid, timestamp, artists = session\n",
    "    artists = list(filter(lambda artist: math.log(artist_counter[artist]) > 2.5, artists))\n",
    "    if len(artists) > 0:\n",
    "        filtered_sessions.append((uid, timestamp, artists))\n",
    "\n",
    "artist_sessions = np.asarray(filtered_sessions)\n",
    "artist_freq_list, artist_counter = get_freq_list(artist_sessions[:, 2])\n",
    "# Частота встречаемости артистов в сессиях\n",
    "_ = plt.hist(artist_freq_list, bins=15)\n",
    "# Всего артистов\n",
    "len(artist_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 1325347/1325347 [00:05<00:00, 223860.86it/s]\n"
     ]
    }
   ],
   "source": [
    "# Сохраним данные для Item2Vec модели\n",
    "# Для ALS и NeuMF понадобится ещё сделать flatten, чтобы получить записи User;Timestamp;Artist\n",
    "pickle.dump(artist_sessions, open('../preprocessed_data/user_timestamp_[artists].pckl', 'wb'))\n",
    "\n",
    "positive_samples = []\n",
    "# Представляем все сессии в виде User;Timestamp;Artist\n",
    "for session in tqdm(artist_sessions):\n",
    "    uid, timestamp, artists = session\n",
    "    session = [(uid, timestamp, artist) for artist in artists]\n",
    "    positive_samples.extend(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Позитивные сэмплы готовы для передачи в модели\n",
    "# Для ALS негативные сэмплы создавать не нужно, тк он сам построит матрицу взаимодействий, и сам будет знать что пользователь \"не оценивал\"\n",
    "# Для NeuMF и UserNeuMF нужно будет явно создать негативные сэмплы и добавить их в датасет\n",
    "# Но для начала разделим данные на train и test согласно timestamp'у"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  44542, 2785601])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Обработка лайков\n",
    "likes_list = pickle.load(open('../preprocessed_data/likes_list.pckl', 'rb'))\n",
    "track_list = pickle.load(open('../preprocessed_data/track_list.pckl', 'rb'))\n",
    "track_to_artist = dict(map(lambda x: (x[0], x[1]), track_list))\n",
    "likes_list = np.asarray(likes_list)[:, :2]\n",
    "likes_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "likes_counter = Counter()\n",
    "for uid, track_id in likes_list:\n",
    "    artist_id = track_to_artist[track_id]\n",
    "    pair = (uid, artist_id)\n",
    "    likes_counter[pair] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "873284"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(likes_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "freq = [math.log(v) for _, v in likes_counter.items()]\n",
    "# Распределение количества лайков на пары (user, artist)\n",
    "_ = plt.hist(freq, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(likes_counter, open('../preprocessed_data/likes_counter.pckl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test-split и выбор метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_dataset = pd.DataFrame(positive_samples, columns=['uid', 'timestamp', 'artist'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Идея разбиения на timestamp - каждому timestamp'у даём некоторый ранг, в пределах от 0 до 1. Всё что ниже 0.9 - train data, выше - test\n",
    "ranks = positive_dataset.groupby('uid')['timestamp'].rank(method='first')\n",
    "counts = positive_dataset['uid'].map(positive_dataset.groupby('uid')['timestamp'].apply(len))\n",
    "result = (ranks / counts) > 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     14842554\n",
       "unique           2\n",
       "top          False\n",
       "freq      11867793\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data, train_data = set(), set()\n",
    "splitter = result.values\n",
    "for i, sample in enumerate(positive_samples, 0):\n",
    "    uid, artist = sample[0], sample[2]\n",
    "    if splitter[i] == True:\n",
    "        test_data.add((uid, artist))\n",
    "    else:\n",
    "        train_data.add((uid, artist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2405220, 848790)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Теперь, когда тестовая и обучающая выборки готовы - выбор метрик\n",
    "# В качестве метрик я выбрал Hit Rate at K и Normalized Discounted Cumulative Gain at K\n",
    "# Когда нужно будет вычислять точность модели, для каждого пользователя из тестовой выборки мы предскажем top-K рекомендаций\n",
    "# И проверим, на сколько совпало с реальными данными в тестовом датасете \n",
    "# мы поделили его по timestamp'у, поэтому можно сказать, что модель должна предсказать интерес пользователя, и мы проверим, как хорошо она справилась"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(train_data, open('../preprocessed_data/train_data.pckl', 'wb'))\n",
    "pickle.dump(test_data, open('../preprocessed_data/test_data.pckl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline - Spark ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pickle.load(open('../preprocessed_data/train_data.pckl', 'rb'))\n",
    "test_data = pickle.load(open('../preprocessed_data/test_data.pckl', 'rb'))\n",
    "negative_samples = flood_negative_samples(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = list(map(lambda x: (x[0], x[1], 1), train_data))\n",
    "negative_samples = list(map(lambda x: (x[0], x[1], 0), negative_samples))\n",
    "train_data.extend(negative_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([StructField('user', IntegerType()), StructField('item', IntegerType()), StructField('rating', IntegerType())])\n",
    "spark_train_rdd = sc.parallelize(train_data)\n",
    "spark_train_df = spark.createDataFrame(spark_train_rdd, schema)\n",
    "spark_test_rdd = sc.parallelize(list(map(lambda x: (x[0], x[1], 1),train_data)))\n",
    "spark_test_df = spark.createDataFrame(spark_test_rdd, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_artist_test_dict = spark_test_df.select(['user', 'item']) \\\n",
    "                                    .rdd.map(lambda x: (x['user'], x['item'])) \\\n",
    "                                    .groupByKey() \\\n",
    "                                    .collectAsMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxIter=20\n",
    "regParam=1\n",
    "rank=10\n",
    "topK = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "als = ALS(rank=rank, maxIter=maxIter, regParam=regParam, coldStartStrategy='drop')\n",
    "als_model = als.fit(spark_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_als(als_model, test_df, user_artist_test_dict):\n",
    "    recommendations = als_model.recommendForUserSubset(test_df.select(['user']), topK).collect()\n",
    "    print('recs are ready')\n",
    "    ndcg_scores = []\n",
    "    hr_scores = []\n",
    "    step = 0\n",
    "    for user, rec in recommendations:\n",
    "        real_items = list(user_artist_test_dict[user])\n",
    "        pred_items = [item[0] for item in rec]\n",
    "        pred_scores = [item[1] for item in rec]\n",
    "        ndcg_score = ndcg(real_items, pred_items, pred_scores)\n",
    "        hr_score = hr(real_items, pred_items)\n",
    "        ndcg_scores.append(ndcg_score)\n",
    "        hr_scores.append(hr_score)\n",
    "    return np.mean(hr_scores), np.mean(ndcg_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recs are ready\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0009764050806849709, 0.0008475165070758779)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_als(als_model, spark_test_df, user_artist_test_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Использование явных рейтингов в Spark ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "likes_counter = pickle.load(open('../preprocessed_data/likes_counter.pckl', 'rb'))\n",
    "likes_data = list(map(lambda k: (int(k[0][0]), int(k[0][1]), int(k[1])), likes_counter.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([StructField('user', IntegerType()), StructField('item', IntegerType()), StructField('rating', IntegerType())])\n",
    "spark_likes_rdd = sc.parallelize(likes_data)\n",
    "spark_likes_df = spark.createDataFrame(spark_likes_rdd, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_likes_train, spark_likes_test = spark_likes_df.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_artist_test_dict = spark_likes_test.select(['user', 'item']) \\\n",
    "                                    .rdd.map(lambda x: (x['user'], x['item'])) \\\n",
    "                                    .groupByKey() \\\n",
    "                                    .collectAsMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxIter=20\n",
    "regParam=0.1\n",
    "rank=10\n",
    "topK = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "als = ALS(rank=rank, maxIter=maxIter, regParam=regParam, coldStartStrategy='drop')\n",
    "als_model = als.fit(spark_likes_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recs are ready\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.00589700553034128, 0.0017013129282348347)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_als(als_model, spark_likes_test, user_artist_test_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NeuMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pickle.load(open('../preprocessed_data/train_data.pckl', 'rb'))\n",
    "validation_data = pickle.load(open('../preprocessed_data/test_data.pckl', 'rb'))\n",
    "# Нужно создать негативные сэмплы для датасета. число 150 выбрано, чтобы создать негативные сэмплы примерно 1:1 с позитивными\n",
    "negative_samples = flood_negative_samples(train_data, validation_data, samples_per_user=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 848790/848790 [00:01<00:00, 643541.29it/s]\n"
     ]
    }
   ],
   "source": [
    "# torch.nn.Embedding работает как таблица и требует, чтобы индексы были в границах [0; Длина словаря]\n",
    "# У нас длина словаря соответственно это количество пользователей и артистов\n",
    "user_mapper, item_mapper = ItemDataset.get_mappers(train_data.union(validation_data))\n",
    "# Позитивные сэмплы теперь будут иметь отметку 1\n",
    "train_data = list(map(lambda x: (x[0], x[1], 1), train_data))\n",
    "# Нетивные соответсвенно 0\n",
    "negative_samples = list(map(lambda x: (x[0], x[1], 0), negative_samples))\n",
    "# Нужно слить данные и поделить на тестовую и обучающую выборку\n",
    "train_data.extend(negative_samples)\n",
    "train, test = train_test_split(train_data, train_size=0.8)\n",
    "\n",
    "train_dataset = ItemDataset(train, user_mapper, item_mapper)\n",
    "test_dataset = ItemDataset(test, user_mapper, item_mapper)\n",
    "# Датасет для валидации на метриках HR@20 и NDCG@20\n",
    "validation_dataset = ValidationDataset(validation_data, user_mapper, item_mapper)\n",
    "BATCH_SIZE = 8192\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15495, 89729)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Соответственно размеры словарей для эмбеддингов\n",
    "len(user_mapper), len(item_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================\n",
      "                  Kernel Shape Output Shape   Params Mult-Adds\n",
      "Layer                                                         \n",
      "0_user_embeddings  [10, 15495]   [1024, 10]  154.95k   154.95k\n",
      "1_item_embeddings  [10, 89729]   [1024, 10]  897.29k   897.29k\n",
      "2_out.Linear_0         [10, 1]    [1024, 1]     11.0      10.0\n",
      "3_out.Sigmoid_1              -    [1024, 1]        -         -\n",
      "----------------------------------------------------------------\n",
      "                         Totals\n",
      "Total params          1.052251M\n",
      "Trainable params      1.052251M\n",
      "Non-trainable params        0.0\n",
      "Mult-Adds              1.05225M\n",
      "================================================================\n",
      "=========================================================================\n",
      "                        Kernel Shape Output Shape      Params   Mult-Adds\n",
      "Layer                                                                    \n",
      "0_user_embeddings       [128, 15495]  [1024, 128]    1.98336M    1.98336M\n",
      "1_item_embeddings       [128, 89729]  [1024, 128]  11.485312M  11.485312M\n",
      "2_hidden.Linear_0         [256, 128]  [1024, 128]     32.896k     32.768k\n",
      "3_hidden.LeakyReLU_1               -  [1024, 128]           -           -\n",
      "4_hidden.Dropout_2                 -  [1024, 128]           -           -\n",
      "5_hidden.Linear_3          [128, 64]   [1024, 64]      8.256k      8.192k\n",
      "6_hidden.LeakyReLU_4               -   [1024, 64]           -           -\n",
      "7_hidden.Dropout_5                 -   [1024, 64]           -           -\n",
      "8_hidden.Linear_6           [64, 32]   [1024, 32]       2.08k      2.048k\n",
      "9_hidden.LeakyReLU_7               -   [1024, 32]           -           -\n",
      "10_hidden.Dropout_8                -   [1024, 32]           -           -\n",
      "11_hidden.Linear_9          [32, 16]   [1024, 16]       528.0       512.0\n",
      "12_hidden.LeakyReLU_10             -   [1024, 16]           -           -\n",
      "13_hidden.Dropout_11               -   [1024, 16]           -           -\n",
      "14_out.Linear_0              [16, 1]    [1024, 1]        17.0        16.0\n",
      "15_out.Sigmoid_1                   -    [1024, 1]           -           -\n",
      "-------------------------------------------------------------------------\n",
      "                          Totals\n",
      "Total params          13.512449M\n",
      "Trainable params      13.512449M\n",
      "Non-trainable params         0.0\n",
      "Mult-Adds             13.512208M\n",
      "=========================================================================\n"
     ]
    }
   ],
   "source": [
    "config = Hparam('config.yaml')\n",
    "gmf_model = GMF(config.gmf)\n",
    "mlp_model = MLP(config.mlp)\n",
    "a, b = [torch.zeros((1024)).long() for _ in range(2)]\n",
    "_ = summary(gmf_model, a, b)\n",
    "_ = summary(mlp_model, a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "gmf_model.to(device)\n",
    "mlp_model.to(device)\n",
    "# Как оптимизатор выбран SGD, тк остальные оптимизаторы используют momentum и сохраняют о нём информацию, а тк NeuMF будем дообучать после соединения моделей\n",
    "# Эта информация будет утеряна и он будет хуже обучаться\n",
    "gmf_optim = torch.optim.SGD(gmf_model.parameters(), lr=0.05)\n",
    "mlp_optim = torch.optim.SGD(mlp_model.parameters(), lr=0.05)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training\n"
     ]
    }
   ],
   "source": [
    "# Обучаем GMF и MLP соответственно\n",
    "train_ncf(gmf_model, train_loader, test_loader, validation_dataset, gmf_optim, criterion, device, writer, config.train_gmf)\n",
    "train_ncf(mlp_model, train_loader, test_loader, validation_dataset, mlp_optim, criterion, device, writer, config.train_mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <img src=\"pics\\gmf_test_loss.png\" width=\"200\" height=\"200\">\n",
    "    <img src=\"pics\\gmf_train_loss.png\" width=\"200\" height=\"200\">\n",
    "</div>\n",
    "<div>\n",
    "    <img src=\"pics\\mlp_test_loss.png\" width=\"200\" height=\"200\">\n",
    "    <img src=\"pics\\mlp_train_loss.png\" width=\"200\" height=\"200\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Соединяем обученые GMF и MLP в NeuMF\n",
    "gmf_path = os.path.join(config.train_gmf.save_path, 'epoch_20.ckpt')\n",
    "mlp_path = os.path.join(config.train_mlp.save_path, 'epoch_20.ckpt')\n",
    "neu_mf = load_pretrained_weights_neu_mf_from_path(gmf_path, config.gmf, mlp_path, config.mlp, config.neu_mf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "neu_mf.to(device)\n",
    "# Уже для NeuMF можно использовать любой оптимизатор - никаких ограничений нет\n",
    "neu_mf_optim = torch.optim.Adam(neu_mf.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training\n"
     ]
    }
   ],
   "source": [
    "train_ncf(neu_mf, train_loader, test_loader, validation_dataset, neu_mf_optim, criterion, device, writer, config.train_neu)\n",
    "# В итоге по графику test loss'a можно увидеть, что модель начала оверфититься около 1.5к итераций - 5 эпоха\n",
    "# При этом трейн падает, поэтому это точно уже оверфит\n",
    "# Поэтому для вычисления метрик можно взять 4 чекпоинт модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <img src=\"pics\\neu_mf_test_loss.png\" width=\"200\" height=\"200\">\n",
    "    <img src=\"pics\\neu_mf_train_loss.png\" width=\"200\" height=\"200\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "neu_mf = NeuMF(config.neu_mf)\n",
    "neu_mf.load_state_dict(torch.load('../model_checkpoints/NCF/NEU/epoch_4.ckpt'))\n",
    "neu_mf.to(device)\n",
    "evaluate_neu(neu_mf, validation_dataset, device, writer, config.train_neu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <img src=\"pics\\neu_mf_hr.png\" width=\"200\" height=\"200\">\n",
    "    <img src=\"pics\\neu_mf_ndcg.png\" width=\"200\" height=\"200\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В итоге с тензоборда можно получить значения:\n",
    "* HR@20 (Max) = 0.7\n",
    "* NDCG@20 (MAX) = 0.771\n",
    "* HR@20 (Mean) = 0.101\n",
    "* NDCG@20 (Mean) = 0.109"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NeuMF with User Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Этот подход будет отличаться только тем, что в MLP модель мы будем добавлять\n",
    "# Фичи связанные с пользователем - возраст, гендер - 0 и 1 (их всего два), id страны, и нормализованное количество прослушиваний\n",
    "# Плюс, как эксперимент, будем пробовать обучать сразу UserNeuMF\n",
    "user_list = pickle.load(open('../preprocessed_data/user_list.pckl', 'rb'))\n",
    "user_features = ItemDataset.user_info_preprocessed(user_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pickle.load(open('../preprocessed_data/train_data.pckl', 'rb'))\n",
    "validation_data = pickle.load(open('../preprocessed_data/test_data.pckl', 'rb'))\n",
    "# negative_samples = flood_negative_samples(train_data, validation_data, samples_per_user=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Шаги все те же, что и для NeuMF, только в датасеты ещё передаём фичи пользователя\n",
    "user_mapper, item_mapper = ItemDataset.get_mappers(train_data.union(validation_data))\n",
    "train_data = list(map(lambda x: (x[0], x[1], 1), train_data))\n",
    "negative_samples = list(map(lambda x: (x[0], x[1], 0), negative_samples))\n",
    "train_data.extend(negative_samples)\n",
    "\n",
    "train, test = train_test_split(train_data, train_size=0.8)\n",
    "\n",
    "train_dataset = ItemDataset(train, user_mapper, item_mapper, user_features)\n",
    "test_dataset = ItemDataset(test, user_mapper, item_mapper, user_features)\n",
    "\n",
    "validation_dataset = ValidationDataset(validation_data, user_mapper, item_mapper, user_features)\n",
    "\n",
    "BATCH_SIZE = 8192\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================\n",
      "                        Kernel Shape Output Shape      Params   Mult-Adds\n",
      "Layer                                                                    \n",
      "0_user_embeddings_mf     [10, 15495]   [1024, 10]     154.95k     154.95k\n",
      "1_item_embeddings_mf     [10, 89729]   [1024, 10]     897.29k     897.29k\n",
      "2_user_embeddings_mlp   [128, 15495]  [1024, 128]    1.98336M    1.98336M\n",
      "3_item_embeddings_mlp   [128, 89729]  [1024, 128]  11.485312M  11.485312M\n",
      "4_hidden.Linear_0         [260, 128]  [1024, 128]     33.408k      33.28k\n",
      "5_hidden.LeakyReLU_1               -  [1024, 128]           -           -\n",
      "6_hidden.Dropout_2                 -  [1024, 128]           -           -\n",
      "7_hidden.Linear_3          [128, 64]   [1024, 64]      8.256k      8.192k\n",
      "8_hidden.LeakyReLU_4               -   [1024, 64]           -           -\n",
      "9_hidden.Dropout_5                 -   [1024, 64]           -           -\n",
      "10_hidden.Linear_6          [64, 32]   [1024, 32]       2.08k      2.048k\n",
      "11_hidden.LeakyReLU_7              -   [1024, 32]           -           -\n",
      "12_hidden.Dropout_8                -   [1024, 32]           -           -\n",
      "13_hidden.Linear_9          [32, 16]   [1024, 16]       528.0       512.0\n",
      "14_hidden.LeakyReLU_10             -   [1024, 16]           -           -\n",
      "15_hidden.Dropout_11               -   [1024, 16]           -           -\n",
      "16_out.Linear_0              [26, 1]    [1024, 1]        27.0        26.0\n",
      "17_out.Sigmoid_1                   -    [1024, 1]           -           -\n",
      "-------------------------------------------------------------------------\n",
      "                          Totals\n",
      "Total params          14.565211M\n",
      "Trainable params      14.565211M\n",
      "Non-trainable params         0.0\n",
      "Mult-Adds              14.56497M\n",
      "=========================================================================\n"
     ]
    }
   ],
   "source": [
    "config = Hparam('config.yaml')\n",
    "user_neu_mf = UserNeuMF(config.neu_mf)\n",
    "a, b = [torch.zeros((1024)).long() for _ in range(2)]\n",
    "c = torch.zeros((1024, 4))\n",
    "_ = summary(user_neu_mf, a, b, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "user_neu_mf.to(device)\n",
    "# Ограничений нет, можем использовать любой оптимизатор\n",
    "user_neu_mf_optim = torch.optim.Adam(user_neu_mf.parameters())\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training\n"
     ]
    }
   ],
   "source": [
    "train_user_neu(user_neu_mf, train_loader, test_loader, validation_dataset, user_neu_mf_optim, criterion, device, writer, config.train_neu)\n",
    "# UserNeuMF постигла участь NeuMF и он заоверфитился после 7 эпохи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_neu_mf.load_state_dict(torch.load('../model_checkpoints/NCF/NEUUSR/epoch_5.ckpt'))\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "user_neu_mf.to(device)\n",
    "writer = SummaryWriter()\n",
    "evaluate_user_neu(user_neu_mf, validation_dataset, device, writer, config.train_neu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В итоге с тензоборда можно получить значения:\n",
    "* HR@20 (Max) = 0.65\n",
    "* NDCG@20 (MAX) = 0.6747\n",
    "* HR@20 (Mean) = 0.09244\n",
    "* NDCG@20 (Mean) = 0.1045"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сравнение моделей и предсказание артистов\n",
    "\n",
    "В сравнении между"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists_list = pickle.load(open('../preprocessed_data/artist_list.pckl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists_map = dict(artists_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_neu_mf.to(torch.device('cpu'))\n",
    "artists = torch.stack([torch.tensor(i).long() for i in range(config.train_neu.item_count)])\n",
    "embeddings = user_neu_mf.item_embeddings_mf(artists)\n",
    "embeddings = [i.detach().numpy() for i in embeddings]\n",
    "nearest_neib = NearestNeighbors().fit(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_mapper = {v:k for k,v in item_mapper.items()}\n",
    "# Найдём исполнителей, похожих на Travis Scott\n",
    "Travis_Idx = item_mapper[287560]\n",
    "travis_embedding = embeddings[Travis_Idx]\n",
    "prediction = nearest_neib.kneighbors([travis_embedding], n_neighbors=20, return_distance=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rammstien\n",
      "The+Mouse+Outfit\n",
      "Noah+Howard+Group\n",
      "Zilch\n",
      "Giacinto+Scelsi\n",
      "Capricorn\n",
      "Hatifnats\n",
      "Southern+Culture+On+The+Skids\n",
      "Clever+Girl\n",
      "Klaus+Badelt\n",
      "Klaus+Sch%C3%B8nning\n",
      "Thelonious+Monk+&+John+Coltrane\n",
      "TeV95\n",
      "Sterling+Holloway\n",
      "Mainstay\n",
      "Death+Wolf\n",
      "Shook\n",
      "Fredo+Viola\n",
      "Die+Streuner\n",
      "The+Soundtrack+Tribute+Band\n"
     ]
    }
   ],
   "source": [
    "for idx in prediction:\n",
    "    artist_id = artist_mapper[idx]\n",
    "    print(list(artists_map[artist_id])[0][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
